{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e41e3cf-f0b4-4537-badc-b2bba3009793",
   "metadata": {},
   "source": [
    "# Question your document using Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22639a8b-4afe-4b3f-97df-b9326a6430fb",
   "metadata": {},
   "source": [
    "I have created a PDF document named 'highway' and saved it in my local drive. The text of the document is:\n",
    "\n",
    "\"I went on my bucket list road trip all the to arctic ocean visa Alaska highway and dempster highway. I live\n",
    "in Edmonton and always wanted to go there as Canada is the only country that has public road to the\n",
    "arctic ocean. I left o may 29 2024 and returned home on june 12 2024. I went to Whitehorse via stewart\n",
    "cassiar highway and on my way back I took Alaska highway from Whitehorse.\"\n",
    "\n",
    "Below we will use Langchain to ask questions about our document. Please note that this is just a demo and in real \n",
    "world examples this can be very powerful tool to get answers from large documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cd91985-3f3d-4200-9c5d-a2d04bbe77ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFDistilBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Edmonton\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from transformers import pipeline\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "import PyPDF2\n",
    "\n",
    "# Function to read PDF and extract text\n",
    "def read_pdf(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            text += pdf_reader.pages[page_num].extract_text()\n",
    "    return text\n",
    "\n",
    "# Function to answer questions using LangChain and a pre-trained model\n",
    "def answer_question_llm(context, question):\n",
    "    # Hugging Face QA pipeline expects input in a dictionary format\n",
    "    qa_input = {\"context\": context, \"question\": question}\n",
    "    \n",
    "    # Wrapping the Hugging Face pipeline with HuggingFacePipeline\n",
    "    hf_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
    "    wrapped_llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
    "    \n",
    "    # Directly using the Hugging Face pipeline for Q&A\n",
    "    answer = hf_pipeline(question=question, context=context)\n",
    "    return answer['answer']\n",
    "\n",
    "# Specify the path to your PDF file\n",
    "pdf_path =  r\"C:\\Users\\Fawad\\highway.pdf\"\n",
    "\n",
    "# Read the PDF file\n",
    "context = read_pdf(pdf_path)\n",
    "\n",
    "# Example question\n",
    "question = \"where do I live?\"\n",
    "\n",
    "# Get the answer\n",
    "answer = answer_question_llm(context, question)\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1245cd68-cbde-48f0-87be-d93c7021d137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
